# Kafka Introduction

## What is Kafka
	Apache Kafka is a message broker and stream processor. Kafka is used to handle real-time data feeds.

Before Kafka, the general architecture would look something like this: 
```
Top: Set of consumers such as Web, Apps, Analytics, Microservices and more

Bottom: Set of data sources or sinks or databases
```
In a data project we can differentiate between consumers and producers:
- Consumers are those that consume the data: web pages, micro services, apps, etc.
- Producers are those who supply the data to consumers.

For example, a web-service is pulling data from a `cache` and pushing the data to a logging service/database. 
The logs are then read by the some microservices and also maybe by monitoring services.

The whole architecture diagram for all this to happen becomes complicated really quickly as many different components such as logging, noSQL, and hadoop are talking to multiple consumers and producers
And this becomes difficult to maintain overtime.

Now, with the introduction of Kafka, the architecture would look something like this:
```
Top: Set of consumers such as Web, Apps, Analytics, Microservices and more

Middle: Apache Kafka

Bottom: Set of data sources or sinks or databases
```

In this case, when our web app produces a message, this message can be directly read by a microservice or a monitoring service from Apache Kafka

Connecting consumers to producers directly can lead to an amorphous and hard to maintain architecture in complex projects like the one in the first image. Kafka solves this issue by becoming an intermediary that all other components connect to.

Kafka works by allowing producers to send messages which are then pushed in real time by Kafka to consumers.
- We can think of Kafka as a message broker or a message service between the data producers and consumers

Kafka is hugely popular and most technology-related companies use it.

## Basic Kafka Components

### Message
The basic communication abstraction used by producers and consumers in order to share information in Kafka is called a message.

Generally, when we are talking about pushing data to Kafka or talking between producers and consumers, this happens over the abstraction called `Messages` in Kafka

**Messages** have 3 main components:

- ***Key***: used to identify the message and for additional Kafka stuff such as partitions, and which direction this message will go into (covered later).
- ***Value***: the actual information that producers push and consumers are interested in.
- ***Timestamp***: used for logging. Can be put by a producer or a consumer

### Topic

A ***topic*** is an abstraction of a concept. Concepts can be anything that makes sense in the context of the project, such as "sales data", "new members", "clicks on banner", etc.

For example, we can have `topic` for `click data` in which there will click related data. And producers will push click related data to this topic, and consumers will consume click related data from this topic

A **producer** pushes a message to a topic, which is then consumed by a **consumer** subscribed to that topic.

### Broker and Cluster

A ***Kafka broker*** is a machine (physical or virtualized) on which Kafka is running.

A ***Kafka cluster*** is a collection of brokers (nodes) working together.

### Logs

In Kafka, ***logs*** are _data segments_ present on a storage disk. In other words, they're _physical representations of data_.

***Logs*** store messages in an ordered fashion. Kafka assigns a sequence ID in order to each new message and then stores it in logs.
- ***Logs*** help us to keep and store our data in Kafka

